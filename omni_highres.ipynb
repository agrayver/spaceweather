{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMNI High-res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OMNI high res data only include the IMF, solar wind speed, and proton density time series, which is why we're focussing now on the low res data. \n",
    "\n",
    "For the low-res data file, nodata quantities are as follows for each variable:\n",
    "- \n",
    "\n",
    "In the high-res .asc files, the columns corresponding to the above quantities are detailed below, where the number in parentheses is the indexing in python:\n",
    "- Bx (GSM) : 15 (14) (nodata = 9999.99)\n",
    "- By (GSM) : 18 (17) (nodata = 9999.99)\n",
    "- Bz (GSM) : 19 (18) (nodata = 9999.99)\n",
    "- Flow speed : 22 (21) (nodata = 99999.9) \n",
    "- Dynamic pressure : 28 (27) (nodata = 99.99)\n",
    "\n",
    "Additionally, we'll need the date information:\n",
    "- Year : 1 (0)\n",
    "- DOY : 2 (1) (will need to convert to mm-dd\n",
    "- Hour : 3 (2)\n",
    "- Minute : 4 (3) (for the high-res data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OMNI high-res\n",
    "Here I load the data from ascii format supplied in the OMNI 5 minute .asc files. I save the data in an HDF5 file, which is much faster to read and write. \n",
    "\n",
    "TO DO: rewrite this with pandas\n",
    "\n",
    "**Only run this cell if that file doesn't exist yet.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data files\n",
    "files = os.listdir('../OMNI_data/highres/')\n",
    "files = [file for file in files if '.asc' in file]\n",
    "\n",
    "# number of files\n",
    "nfiles = len(files)\n",
    "# which columns we need (see above)\n",
    "usecols = [0,1,2,3,14,17,18,21,27]\n",
    "# array to hold data\n",
    "data = np.zeros((0,len(usecols)))\n",
    "\n",
    "for file in files:\n",
    "    curfile = open(os.path.join('../OMNI_data/',file),'r')\n",
    "    curdata = np.genfromtxt(curfile,usecols=usecols)\n",
    "    data = np.concatenate((data,curdata),axis=0)\n",
    "    \n",
    "# get python datetimes\n",
    "t = OMNI2python_date(data[:,0:4])  \n",
    "# replace OMNI dates with python dates\n",
    "data = np.concatenate((t,data[:,4:]))\n",
    "# sort in ascending time\n",
    "data = data[data[:,0].argsort()]\n",
    "\n",
    "# create and save hdf5 file\n",
    "h5f = h5py.File('../OMNI_data/omni_5min_1981-2017_BVP.h5','w')\n",
    "h5f.create_dataset('B-V-P',data=data)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('../OMNI_data/omni_5min_1981-2017_BVP.h5','r')\n",
    "omni_hr = h5f['B-V-P'][:]\n",
    "h5f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
